{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXl2uIwyMqlOEsK2z73ey3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTt8FqKz6QMe"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq tensorflow_hub pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq tensorflow-io"
      ],
      "metadata": {
        "id": "dCZRObc26s_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "#Load the YAMNET model\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "#Load an audio file\n",
        "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audio/h1.wav')\n",
        "audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "#Generate embeddings\n",
        "scores, embeddings, log_mel_spectrogram = model(audio)\n",
        "print(f\"Audio embedding shape: {embeddings.shape}\")"
      ],
      "metadata": {
        "id": "kwfROY_S63Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audio/a1.wav')\n",
        "audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "\n",
        "scores, embeddings, log_mel_spectrogram = model(audio)\n",
        "print(f\"Audio embedding shape: {embeddings.shape}\")"
      ],
      "metadata": {
        "id": "RR0Ez7zW-f2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_mel_spectrogram"
      ],
      "metadata": {
        "id": "UVH9Nr4E-ofP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "voices = []\n",
        "labels = []\n",
        "\n",
        "for i in os.listdir('./audio/'):\n",
        "    #if i.endswith('.wav'):\n",
        "    if '.wav' in i:\n",
        "        name = i.split('.')[0]\n",
        "\n",
        "        audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(f'./audio/{i}'))\n",
        "        audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "        scores, embeddings, log_mel_spectrogram = model(audio)\n",
        "\n",
        "        voices.append(np.array(embeddings[:5,:]).ravel())\n",
        "        labels.append(name)\n",
        "\n",
        "        print(f\"Audio embedding shape: {embeddings.shape} new shape: {embeddings[:5,:].shape} type: {np.array(embeddings[:5,:]).ravel().shape}\")\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "3gjGJP4s-xdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voices"
      ],
      "metadata": {
        "id": "s-0m9baSAw0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports a PyMilvus package\n",
        "from pymilvus import {\n",
        "    connections,\n",
        "    utility,\n",
        "    FieldSchema,\n",
        "    CollectionSchema,\n",
        "    DataType,\n",
        "    Collection,\n",
        "}\n",
        "\n",
        "#Connect to Milvus\n",
        "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
        "\n",
        "#Define the collection name\n",
        "collection_name = \"audio\"\n",
        "\n",
        "#Check if the collection already exists, and drop it if it does\n",
        "if utility.has_collection(collection_name):\n",
        "    Collection(collection_name).drop()\n",
        "\n",
        "\n",
        "#Create a collection\n",
        "fields = [\n",
        "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
        "    FieldSchema(name=\"words\", dtype=DataType.VARCHAR, max_length=50),\n",
        "    FieldSchema(name=\"person_name\", dtype=DataType.VARCHAR, max_length=50),\n",
        "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=5120),\n",
        "]\n",
        "schema = CollectionSchema(fields, \"Simple demo for audio similar search\")\n",
        "audio = Collection(\"audio\", schema)"
      ],
      "metadata": {
        "id": "byM0gYzBA38N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build indexes on the entities\n",
        "index = {\n",
        "    \"index_type\": \"IVF_FLAT\",\n",
        "    \"metric_type\": \"L2\",\n",
        "    \"params\": {\"nlist\": 128},\n",
        "}\n",
        "audio.create_index(\"embeddings\", index)\n",
        "}"
      ],
      "metadata": {
        "id": "BbL-keRTDHKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "4OgOb1E7DamD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voices[0].shape"
      ],
      "metadata": {
        "id": "IcRRLvH4Dc4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inset data in collection\n",
        "data = [\n",
        "    [1,2,3,4,5,6], #pk field\n",
        "    labels,\n",
        "    [\"Auranzaib\", \"Auranzaib\", \"Hasnant\", \"Qasim\", \"Hasnant\", \"Qasim\"],\n",
        "    voices, # embedding field\n",
        "]"
      ],
      "metadata": {
        "id": "hp-b0MvVDlsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio.insert(data)\n",
        "audio.flush()\n",
        "audio.load()"
      ],
      "metadata": {
        "id": "sNTJLNcBEVg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_params = {\"metric_type\": \"L2\"}"
      ],
      "metadata": {
        "id": "3f6rmkNdEfl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = audio.search(\n",
        "    data=[voices[0]],\n",
        "    anns_field=\"embeddings\",\n",
        "    param=search_params,\n",
        "    limit=4,\n",
        "    expr=None,\n",
        "    output_fields=['words','person_name'],\n",
        "    consistency_level=\"Strong\"\n",
        ")"
      ],
      "metadata": {
        "id": "qcBOcReZEn5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(results[0])):\n",
        "  name = results[0][i].entity.get('words')\n",
        "  pname = results[0][i].entity.get('person_name')\n",
        "  print(pname)"
      ],
      "metadata": {
        "id": "6kWehbecjbW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}